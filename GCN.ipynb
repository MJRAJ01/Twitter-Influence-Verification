{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf42f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96d7c4",
   "metadata": {},
   "source": [
    "attributes should be on nodes, not edges. parse/read_edgelist will place attributes on edges.\n",
    "one file with edgelist, one file with nodes and their attributes. can combine these easily to create a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b351db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('Datasets/hedden_network_with_followers_verified.csv', \"r\")\n",
    "next(data, None)  # skip the first line in the input file\n",
    "DiGraph = nx.DiGraph()\n",
    "\n",
    "G = nx.parse_edgelist(data, delimiter=',', create_using=DiGraph,\n",
    "                      nodetype=int, data=(('weight', float),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d42301",
   "metadata": {},
   "source": [
    "in the meantime - use a dummy digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a4abb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n",
      "number of verified nodes: 4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_nodes = 1000\n",
    "prob = 0.001\n",
    "DummyGraph = nx.erdos_renyi_graph(n=num_nodes, p=prob, directed=True)\n",
    "attr_dict = {}\n",
    "for n in range(num_nodes):\n",
    "    # get followers\n",
    "    f = len(DummyGraph.pred[n])\n",
    "    # simple weighted random assignment of verified status\n",
    "    v = False\n",
    "    if f/num_nodes > random.uniform(0,1):\n",
    "        v = True\n",
    "    attr_dict[n] = {\"followers\": f, \"verified\": v}\n",
    "\n",
    "nx.set_node_attributes(DummyGraph, attr_dict)\n",
    "\n",
    "# test\n",
    "print(DummyGraph.nodes[0][\"followers\"])\n",
    "print(DummyGraph.nodes[0][\"verified\"])\n",
    "verified = nx.get_node_attributes(DummyGraph, \"verified\")\n",
    "print(\"number of verified nodes:\", sum(verified.values()))\n",
    "\n",
    "nx.write_gexf(DummyGraph, \"test.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa48975",
   "metadata": {},
   "source": [
    "Convert .csv network to .gexf file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d4d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "data = open('cs4352-final-project/Scraping/dejan.csv', \"r\")\n",
    "G = nx.DiGraph()\n",
    "\n",
    "SoccerGraph = nx.parse_edgelist(data, delimiter=' ', create_using=G)\n",
    "nx.write_gexf(SoccerGraph, \"dejan_gephi.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bc40f",
   "metadata": {},
   "source": [
    "Convert .gml network to .gexf file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58892b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SoccerGraph = nx.read_gml(\"Scraping/Dejan-Full-Node-Info.gml\")\n",
    "SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "nx.write_gexf(SoccerGraph, \"dejan_full_node_info.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded33ef",
   "metadata": {},
   "source": [
    "Inspect individual node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f440573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SoccerGraph.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43029ed2",
   "metadata": {},
   "source": [
    "GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96296caa",
   "metadata": {},
   "source": [
    "Convert networkx graph to dataset accessible by pytorch, cast all floats to integers (Longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c94df4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 7258], y=[685], name=[685], screen_name=[685], protected=[685], geo_enabled=[685], contributors_enabled=[685], is_translator=[685], is_translation_enabled=[685], profile_use_background_image=[685], has_extended_profile=[685], default_profile=[685], default_profile_image=[685], id=[685], x=[685, 5])\n",
      "5\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "SoccerGraph = nx.read_gml(\"Scraping/Dejan-Full-Node-Info.gml\")\n",
    "SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in SoccerGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "data = from_networkx(SoccerGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "print(data)\n",
    "\n",
    "# equivalent of dataset.num_node_features\n",
    "num_node_features = len(data.x[0])\n",
    "num_classes = 2 # verified (y) is binary\n",
    "print(num_node_features)\n",
    "\n",
    "\n",
    "# TRYING TO FIX 'expected scalar type Long but found Float' error\n",
    "for i in range(len(data.x)):\n",
    "    data.x[i] = data.x[i].type(torch.FloatTensor)\n",
    "    \n",
    "data.x = data.x.type(torch.FloatTensor)\n",
    "print(data.x.dtype)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ddf66",
   "metadata": {},
   "source": [
    "Split up data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9164a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "train_ratio = 0.8\n",
    "num_nodes = data.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "import numpy as np\n",
    "np.random.shuffle(idx)\n",
    "train_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "test_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "test_mask[idx[num_train:]] = True\n",
    "data['train_mask'] = train_mask\n",
    "data['test_mask'] = test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f108e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "tensor([[   160,    819,      0,   6881,    251],\n",
      "        [    83,    937,      0,   4160,    106],\n",
      "        [   221,    790,      0,   3927,   2038],\n",
      "        ...,\n",
      "        [   319,    392,      4,   5284,   4587],\n",
      "        [   606,   2088,      3, 440321,   6319],\n",
      "        [   228,    767,      5,  44066,   1007]])\n"
     ]
    }
   ],
   "source": [
    "# no floats in x\n",
    "for r in data.x:\n",
    "    if torch.is_floating_point(r):\n",
    "        print(\"float row\")\n",
    "        \n",
    "print(data.y.dtype)\n",
    "if torch.is_floating_point(data.y):\n",
    "    print(\"float\")\n",
    "        \n",
    "# remove unnecessary lists\n",
    "data.__delattr__('name')\n",
    "data.__delattr__('screen_name')\n",
    "data.__delattr__('protected')\n",
    "data.__delattr__('geo_enabled')\n",
    "data.__delattr__('contributors_enabled')\n",
    "data.__delattr__('is_translator')\n",
    "data.__delattr__('is_translation_enabled')\n",
    "data.__delattr__('profile_use_background_image')\n",
    "data.__delattr__('has_extended_profile')\n",
    "data.__delattr__('default_profile')\n",
    "data.__delattr__('default_profile_image')\n",
    "data.__delattr__('id')\n",
    "print(data.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a65852",
   "metadata": {},
   "source": [
    "Define GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9fd3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train partially on a general twitter network, and then finetune for each specific network?\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class Twitter_GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # two hidden layers\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "# data.validate(raise_on_error=True)\n",
    "\n",
    "model = Twitter_GCN().to(device) \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47befadb",
   "metadata": {},
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65c1c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9052bf5",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a622272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd0a64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
