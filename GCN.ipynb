{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf42f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96d7c4",
   "metadata": {},
   "source": [
    "attributes should be on nodes, not edges. parse/read_edgelist will place attributes on edges.\n",
    "one file with edgelist, one file with nodes and their attributes. can combine these easily to create a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b351db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('Datasets/hedden_network_with_followers_verified.csv', \"r\")\n",
    "next(data, None)  # skip the first line in the input file\n",
    "DiGraph = nx.DiGraph()\n",
    "\n",
    "G = nx.parse_edgelist(data, delimiter=',', create_using=DiGraph,\n",
    "                      nodetype=int, data=(('weight', float),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d42301",
   "metadata": {},
   "source": [
    "in the meantime - use a dummy digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a4abb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "False\n",
      "number of verified nodes: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_nodes = 1000\n",
    "prob = 0.001\n",
    "DummyGraph = nx.erdos_renyi_graph(n=num_nodes, p=prob, directed=True)\n",
    "attr_dict = {}\n",
    "for n in range(num_nodes):\n",
    "    # get followers\n",
    "    f = len(DummyGraph.pred[n])\n",
    "    # simple weighted random assignment of verified status\n",
    "    v = False\n",
    "    if f/num_nodes > random.uniform(0,1):\n",
    "        v = True\n",
    "    attr_dict[n] = {\"followers\": f, \"verified\": v}\n",
    "\n",
    "nx.set_node_attributes(DummyGraph, attr_dict)\n",
    "\n",
    "# test\n",
    "print(DummyGraph.nodes[0][\"followers\"])\n",
    "print(DummyGraph.nodes[0][\"verified\"])\n",
    "verified = nx.get_node_attributes(DummyGraph, \"verified\")\n",
    "print(\"number of verified nodes:\", sum(verified.values()))\n",
    "\n",
    "nx.write_gexf(DummyGraph, \"test.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96bf05",
   "metadata": {},
   "source": [
    "Convert .csv network to .gexf file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71dcccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "data = open('cs4352-final-project/Scraping/dejan.csv', \"r\")\n",
    "G = nx.DiGraph()\n",
    "\n",
    "SoccerGraph = nx.parse_edgelist(data, delimiter=' ', create_using=G)\n",
    "nx.write_gexf(SoccerGraph, \"dejan_gephi.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293fc2c",
   "metadata": {},
   "source": [
    "Convert .gml network to .gexf file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bacadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SoccerGraph = nx.read_gml(\"Scraping/Dejan-Full-Node-Info.gml\")\n",
    "SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "nx.write_gexf(SoccerGraph, \"dejan_full_node_info.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c217f0",
   "metadata": {},
   "source": [
    "Inspect individual node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251e7697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SoccerGraph.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43029ed2",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bad8ad",
   "metadata": {},
   "source": [
    "Convert networkx graph to dataset accessible by pytorch, cast all floats to integers (Longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc804edd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 7258], y=[685], name=[685], screen_name=[685], protected=[685], geo_enabled=[685], contributors_enabled=[685], is_translator=[685], is_translation_enabled=[685], profile_use_background_image=[685], has_extended_profile=[685], default_profile=[685], default_profile_image=[685], id=[685], x=[685, 5])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "SoccerGraph = nx.read_gml(\"Scraping/Dejan-Full-Node-Info.gml\")\n",
    "SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in SoccerGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "data = from_networkx(SoccerGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "print(data)\n",
    "\n",
    "# equivalent of dataset.num_node_features\n",
    "num_node_features = len(data.x[0])\n",
    "num_classes = 2 # verified (y) is binary\n",
    "print(num_node_features)\n",
    "\n",
    "# TRYING TO FIX 'expected scalar type Long but found Float' error\n",
    "# for i in range(len(data.x)):\n",
    "#     data.x[i] = data.x[i].type(torch.FloatTensor)\n",
    "    \n",
    "# CRUCIAL\n",
    "data.x = data.x.type(torch.FloatTensor)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc23ec4",
   "metadata": {},
   "source": [
    "Split up data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218dc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "# ps 3 - train 140, val 500, test 1000\n",
    "# pytorch docs: 'As a rule of thumb, we use 20% of the training set as the validation set.'\n",
    "\n",
    "# Going with 60 training, 20 val, 20 test\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "num_nodes = data.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "num_val = int(num_nodes * val_ratio)\n",
    "num_test = 1 - num_train - num_val\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "import numpy as np\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "\n",
    "val_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "val_mask[idx[num_train:num_train+num_val]] = True\n",
    "\n",
    "test_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "test_mask[idx[num_train+num_val:]] = True\n",
    "\n",
    "data['train_mask'] = train_mask\n",
    "data['val_mask'] = val_mask\n",
    "data['test_mask'] = test_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00614eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 274\n",
      "137 548\n",
      "137 548\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "count_false = 0\n",
    "for n in data.train_mask:\n",
    "    if n:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true, count_false)\n",
    "count_true = 0\n",
    "count_false = 0\n",
    "for n in data.val_mask:\n",
    "    if n:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true, count_false)\n",
    "count_true = 0\n",
    "count_false = 0\n",
    "for n in data.test_mask:\n",
    "    if n:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true, count_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc2e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 7258], y=[685], x=[685, 5], train_mask=[685], val_mask=[685], test_mask=[685])\n"
     ]
    }
   ],
   "source": [
    "# remove unnecessary lists\n",
    "data.__delattr__('name')\n",
    "data.__delattr__('screen_name')\n",
    "data.__delattr__('protected')\n",
    "data.__delattr__('geo_enabled')\n",
    "data.__delattr__('contributors_enabled')\n",
    "data.__delattr__('is_translator')\n",
    "data.__delattr__('is_translation_enabled')\n",
    "data.__delattr__('profile_use_background_image')\n",
    "data.__delattr__('has_extended_profile')\n",
    "data.__delattr__('default_profile')\n",
    "data.__delattr__('default_profile_image')\n",
    "data.__delattr__('id')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf0138",
   "metadata": {},
   "source": [
    "Define GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fd3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train partially on a general twitter network, and then finetune for each specific network?\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class Twitter_GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # two hidden layers\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "# data.validate(raise_on_error=True)\n",
    "\n",
    "model = Twitter_GCN().to(device) \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd942631",
   "metadata": {},
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79bd8ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b85375",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "195c9169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "# FROM DATASET IN PROB 3 LOOKS LIKE 20% IS USED TO TRAIN AND 80% TO TEST INSTEAD OF VICE VERSA -- \n",
    "# IS THIS WHY ACCURACY IS SO HIGH??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64257141",
   "metadata": {},
   "source": [
    "change to val_mask and tune hyperparameters just like hw 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58cfa143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0 0.001\n",
      "Accuracy: 1.0000\n",
      "2 0 0.001\n",
      "Accuracy: 0.9708\n",
      "2 0 0.001\n",
      "Accuracy: 1.0000\n",
      "2 0 0.001\n",
      "Accuracy: 1.0000\n",
      "2 0 0.001\n",
      "Accuracy: 0.9489\n",
      "2 0 0.01\n",
      "Accuracy: 1.0000\n",
      "2 0 0.01\n",
      "Accuracy: 1.0000\n",
      "2 0 0.01\n",
      "Accuracy: 1.0000\n",
      "2 0 0.01\n",
      "Accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out[data\u001b[38;5;241m.\u001b[39mtrain_mask], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[1;32m     47\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [22], line 19\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:175\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    173\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:67\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     65\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     66\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[0;32m---> 67\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     69\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_scatter/scatter.py:29\u001b[0m, in \u001b[0;36mscatter_add\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter_add\u001b[39m(src: torch\u001b[38;5;241m.\u001b[39mTensor, index: torch\u001b[38;5;241m.\u001b[39mTensor, dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     27\u001b[0m                 out: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     28\u001b[0m                 dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_scatter/scatter.py:11\u001b[0m, in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter_sum\u001b[39m(src: torch\u001b[38;5;241m.\u001b[39mTensor, index: torch\u001b[38;5;241m.\u001b[39mTensor, dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m                 out: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                 dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 11\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m         size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_scatter/utils.py:4\u001b[0m, in \u001b[0;36mbroadcast\u001b[0;34m(src, other, dim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast\u001b[39m(src: torch\u001b[38;5;241m.\u001b[39mTensor, other: torch\u001b[38;5;241m.\u001b[39mTensor, dim: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m         dim \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m+\u001b[39m dim\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(GCNConv(num_node_features, 16))\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(GCNConv(16, 16))\n",
    "        self.layers.append(GCNConv(16, num_classes))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "num_layers = [2, 3]\n",
    "l2_regs = [0, 0.0001, 0.001]\n",
    "learning_rates = [0.001, 0.01, 0.05]\n",
    "\n",
    "NUM_ITERS = 5\n",
    "\n",
    "all_trials = []\n",
    "for n in num_layers:            \n",
    "    for l2_reg in l2_regs:\n",
    "        for learning_rate in learning_rates:\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for i in range(NUM_ITERS):\n",
    "                model = GCN(n).to(device)\n",
    "                \n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "\n",
    "                model.train()\n",
    "                for epoch in range(200):\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                model.eval()\n",
    "                pred = model(data).argmax(dim=1)\n",
    "                correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "                acc = int(correct) / int(data.val_mask.sum())\n",
    "                print(n, l2_reg, learning_rate)\n",
    "                print(f'Accuracy: {acc:.4f}')\n",
    "                \n",
    "                results.append(acc)\n",
    "                \n",
    "            avg = sum(results) / len(results)\n",
    "            stdev = statistics.pstdev(results)\n",
    "            all_trials.append(((n, l2_reg, learning_rate), avg, stdev))\n",
    "\n",
    "print((\"Number of layers\", \"L2 regularization\", \"Learning rate\"), \"Average\", \"Standard Dev.\")\n",
    "for t in all_trials:\n",
    "    print(t)\n",
    "\n",
    "max = max(all_trials, key=lambda x:x[1])\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f8921",
   "metadata": {},
   "source": [
    "do linear regression model to compare w/ GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97de2b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.4021911191578005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression().fit(data.x, data.y)\n",
    "\n",
    "r_sq = model.score(data.x, data.y)\n",
    "print(f\"coefficient of determination: {r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844ed57",
   "metadata": {},
   "source": [
    "can we train a model on one twitter network and then apply it to other people's networks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
