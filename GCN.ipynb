{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf42f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96d7c4",
   "metadata": {},
   "source": [
    "attributes should be on nodes, not edges. parse/read_edgelist will place attributes on edges.\n",
    "one file with edgelist, one file with nodes and their attributes. can combine these easily to create a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b351db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = open('Datasets/hedden_network_with_followers_verified.csv', \"r\")\n",
    "# next(data, None)  # skip the first line in the input file\n",
    "# DiGraph = nx.DiGraph()\n",
    "\n",
    "# G = nx.parse_edgelist(data, delimiter=',', create_using=DiGraph,\n",
    "#                       nodetype=int, data=(('weight', float),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d42301",
   "metadata": {},
   "source": [
    "in the meantime - use a dummy digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4abb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_nodes = 1000\n",
    "prob = 0.001\n",
    "DummyGraph = nx.erdos_renyi_graph(n=num_nodes, p=prob, directed=True)\n",
    "attr_dict = {}\n",
    "for n in range(num_nodes):\n",
    "    # get followers\n",
    "    f = len(DummyGraph.pred[n])\n",
    "    # simple weighted random assignment of verified status\n",
    "    v = False\n",
    "    if random.uniform(0,1) > 0.5:\n",
    "        v = True\n",
    "    attr_dict[n] = {\"followers\": f, \"verified\": v}\n",
    "\n",
    "nx.set_node_attributes(DummyGraph, attr_dict)\n",
    "\n",
    "# test\n",
    "print(DummyGraph.nodes[0][\"followers\"])\n",
    "print(DummyGraph.nodes[0][\"verified\"])\n",
    "verified = nx.get_node_attributes(DummyGraph, \"verified\")\n",
    "print(\"number of verified nodes:\", sum(verified.values()))\n",
    "\n",
    "nx.write_gexf(DummyGraph, \"test.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96bf05",
   "metadata": {},
   "source": [
    "Convert .csv network to .gexf file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "data = open('cs4352-final-project/Scraping/dejan.csv', \"r\")\n",
    "G = nx.DiGraph()\n",
    "\n",
    "SoccerGraph = nx.parse_edgelist(data, delimiter=' ', create_using=G)\n",
    "nx.write_gexf(SoccerGraph, \"dejan_gephi.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293fc2c",
   "metadata": {},
   "source": [
    "Convert .gml network to .gexf file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bacadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SoccerGraph = nx.read_gml(\"Scraping/Dejan-Full-Node-Info.gml\")\n",
    "SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "nx.write_gexf(SoccerGraph, \"dejan_full_node_info.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c217f0",
   "metadata": {},
   "source": [
    "Inspect individual node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e7697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(SoccerGraph.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43029ed2",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bad8ad",
   "metadata": {},
   "source": [
    "Convert networkx graph to dataset accessible by pytorch, cast all floats to integers (Longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc804edd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "SoccerGraph = nx.read_gml(\"Scraping/Dejan-Full-Node-Info.gml\")\n",
    "SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in SoccerGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "data = from_networkx(SoccerGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "print(data)\n",
    "\n",
    "# equivalent of dataset.num_node_features\n",
    "num_node_features = len(data.x[0])\n",
    "num_classes = 2 # verified (y) is binary\n",
    "print(num_node_features)\n",
    "\n",
    "# TRYING TO FIX 'expected scalar type Long but found Float' error\n",
    "# for i in range(len(data.x)):\n",
    "#     data.x[i] = data.x[i].type(torch.FloatTensor)\n",
    "    \n",
    "# CRUCIAL\n",
    "data.x = data.x.type(torch.FloatTensor)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc23ec4",
   "metadata": {},
   "source": [
    "Split up data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218dc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "# ps 3 - train 140, val 500, test 1000\n",
    "# pytorch docs: 'As a rule of thumb, we use 20% of the training set as the validation set.'\n",
    "\n",
    "# Going with 60 training, 20 val, 20 test\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "num_nodes = data.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "num_val = int(num_nodes * val_ratio)\n",
    "num_test = 1 - num_train - num_val\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "import numpy as np\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "\n",
    "val_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "val_mask[idx[num_train:num_train+num_val]] = True\n",
    "\n",
    "test_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "test_mask[idx[num_train+num_val:]] = True\n",
    "\n",
    "data['train_mask'] = train_mask\n",
    "data['val_mask'] = val_mask\n",
    "data['test_mask'] = test_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00614eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_true = 0\n",
    "count_false = 0\n",
    "for n in data.train_mask:\n",
    "    if n:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true, count_false)\n",
    "count_true = 0\n",
    "count_false = 0\n",
    "for n in data.val_mask:\n",
    "    if n:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true, count_false)\n",
    "count_true = 0\n",
    "count_false = 0\n",
    "for n in data.test_mask:\n",
    "    if n:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true, count_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03358775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure train test val don't overlap\n",
    "for i in range(num_nodes):\n",
    "    if val_mask[i] and train_mask[i] or val_mask[i] and test_mask[i] or train_mask[i] and test_mask[i]:\n",
    "        print('overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary lists\n",
    "data.__delattr__('name')\n",
    "data.__delattr__('screen_name')\n",
    "data.__delattr__('protected')\n",
    "data.__delattr__('geo_enabled')\n",
    "data.__delattr__('contributors_enabled')\n",
    "data.__delattr__('is_translator')\n",
    "data.__delattr__('is_translation_enabled')\n",
    "data.__delattr__('profile_use_background_image')\n",
    "data.__delattr__('has_extended_profile')\n",
    "data.__delattr__('default_profile')\n",
    "data.__delattr__('default_profile_image')\n",
    "data.__delattr__('id')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf0138",
   "metadata": {},
   "source": [
    "Define GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train partially on a general twitter network, and then finetune for each specific network?\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class Twitter_GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # two hidden layers\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "# data.validate(raise_on_error=True)\n",
    "\n",
    "model = Twitter_GCN().to(device) \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd942631",
   "metadata": {},
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd8ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b85375",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "# FROM DATASET IN PROB 3 LOOKS LIKE 20% IS USED TO TRAIN AND 80% TO TEST INSTEAD OF VICE VERSA -- \n",
    "# IS THIS WHY ACCURACY IS SO HIGH??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64257141",
   "metadata": {},
   "source": [
    "change to val_mask and tune hyperparameters just like hw 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfa143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(GCNConv(num_node_features, 16))\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(GCNConv(16, 16))\n",
    "        self.layers.append(GCNConv(16, num_classes))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "num_layers = [2, 10]\n",
    "l2_regs = [0, 0.0001, 0.00000000001]\n",
    "learning_rates = [0.9, 0.01, 0.001]\n",
    "\n",
    "NUM_ITERS = 2\n",
    "\n",
    "all_trials = []\n",
    "for n in num_layers:            \n",
    "    for l2_reg in l2_regs:\n",
    "        for learning_rate in learning_rates:\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for i in range(NUM_ITERS):\n",
    "                model = Twitter_GCN().to(device)\n",
    "                \n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "\n",
    "                model.train()\n",
    "                for epoch in range(200):\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                model.eval()\n",
    "                pred = model(data).argmax(dim=1)\n",
    "                correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "                acc = int(correct) / int(data.val_mask.sum())\n",
    "                print(n, l2_reg, learning_rate)\n",
    "                print(f'Accuracy: {acc:.4f}')\n",
    "                \n",
    "                results.append(acc)\n",
    "                \n",
    "            avg = sum(results) / len(results)\n",
    "            stdev = statistics.pstdev(results)\n",
    "            all_trials.append(((n, l2_reg, learning_rate), avg, stdev))\n",
    "\n",
    "print((\"Number of layers\", \"L2 regularization\", \"Learning rate\"), \"Average\", \"Standard Dev.\")\n",
    "for t in all_trials:\n",
    "    print(t)\n",
    "\n",
    "max = max(all_trials, key=lambda x:x[1])\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f8921",
   "metadata": {},
   "source": [
    "linear regression model as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de2b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression().fit(data.x, data.y)\n",
    "\n",
    "r_sq = model.score(data.x, data.y)\n",
    "print(f\"coefficient of determination: {r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c981c9f",
   "metadata": {},
   "source": [
    "do neural net without graph info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3952d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9844ed57",
   "metadata": {},
   "source": [
    "train a model on each network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92669f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dejan\n",
      "Accuracy: 0.9757\n",
      "mccormick\n",
      "Accuracy: 0.9009\n",
      "hedden\n",
      "Accuracy: 0.8136\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "def mask_data(data, train_ratio, val_ratio):\n",
    "\n",
    "    test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "    num_nodes = data.x.shape[0]\n",
    "    num_train = int(num_nodes * train_ratio)\n",
    "    num_val = int(num_nodes * val_ratio)\n",
    "    num_test = 1 - num_train - num_val\n",
    "    idx = [i for i in range(num_nodes)]\n",
    "\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    train_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "    train_mask[idx[:num_train]] = True\n",
    "\n",
    "    val_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "    val_mask[idx[num_train:num_train+num_val]] = True\n",
    "\n",
    "    test_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "    test_mask[idx[num_train+num_val:]] = True\n",
    "\n",
    "    data['train_mask'] = train_mask\n",
    "    data['val_mask'] = val_mask\n",
    "    data['test_mask'] = test_mask\n",
    "    \n",
    "\n",
    "class Twitter_GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super().__init__()\n",
    "        # two hidden layers\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "\n",
    "\n",
    "def GCN_on_Twitter_Graph(gml_file):\n",
    "    SoccerGraph = nx.read_gml(gml_file)\n",
    "    SoccerGraph = nx.convert_node_labels_to_integers(SoccerGraph, label_attribute=\"id\")\n",
    "\n",
    "    # rename verified to y attribute (verified) to graph before conversion \n",
    "    for n, data in SoccerGraph.nodes(data=True):\n",
    "        data[\"y\"] = data.pop('verified')\n",
    "\n",
    "    data = from_networkx(SoccerGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "#     data = from_networkx(SoccerGraph, group_node_attrs=['followers'])\n",
    "\n",
    "    num_node_features = len(data.x[0])\n",
    "    num_classes = 2\n",
    "\n",
    "    data.x = data.x.type(torch.FloatTensor)\n",
    "    \n",
    "    train_ratio = 0.4\n",
    "    val_ratio = 0.3\n",
    "    mask_data(data, train_ratio, val_ratio)\n",
    "    \n",
    "#     print(data)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    data.validate(raise_on_error=True)\n",
    "\n",
    "    model = Twitter_GCN(num_node_features,num_classes).to(device) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # train on own model\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "    \n",
    "    \n",
    "print('dejan')\n",
    "GCN_on_Twitter_Graph('Scraping/Dejan-Full-Node-Info.gml')\n",
    "print('mccormick')\n",
    "GCN_on_Twitter_Graph('Scraping/McCormick.gml')\n",
    "print('hedden')\n",
    "GCN_on_Twitter_Graph('Scraping/Hedden.gml')\n",
    "# print('FAKE')\n",
    "# GCN_on_Twitter_Graph('fakeNetwork.gml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda4ba1",
   "metadata": {},
   "source": [
    "test each model on the other networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89dfb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained on dejan_________\n",
      "Dejan, McCormick, Hedden\n",
      "Accuracy on trained on model: 0.9854\n",
      "Accuracy on other model: 0.8765\n",
      "Accuracy on other other model: 0.8201\n",
      "trained on mccormick_________\n",
      "McCormick, Dejan, Hedden\n",
      "Accuracy on trained on model: 0.7206\n",
      "Accuracy on other model: 0.6161\n",
      "Accuracy on other other model: 0.7253\n",
      "trained on hedden_________\n",
      "Hedden, Dejan, McCormick\n",
      "Accuracy on trained on model: 0.9143\n",
      "Accuracy on other model: 0.9869\n",
      "Accuracy on other other model: 0.8814\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.4\n",
    "val_ratio = 0.3\n",
    "\n",
    "DejanGraph = nx.read_gml('Scraping/Dejan-Full-Node-Info.gml')\n",
    "DejanGraph = nx.convert_node_labels_to_integers(DejanGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in DejanGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "DejanData = from_networkx(DejanGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "#     data = from_networkx(SoccerGraph, group_node_attrs=['followers'])\n",
    "\n",
    "num_node_features = len(DejanData.x[0])\n",
    "num_classes = 2\n",
    "\n",
    "DejanData.x = DejanData.x.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "McCormickGraph = nx.read_gml('Scraping/McCormick.gml')\n",
    "McCormickGraph = nx.convert_node_labels_to_integers(McCormickGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in McCormickGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "McCormickData = from_networkx(McCormickGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "#     data = from_networkx(SoccerGraph, group_node_attrs=['followers'])\n",
    "\n",
    "num_node_features = len(McCormickData.x[0])\n",
    "num_classes = 2\n",
    "\n",
    "McCormickData.x = McCormickData.x.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "HeddenGraph = nx.read_gml('Scraping/Hedden.gml')\n",
    "HeddenGraph = nx.convert_node_labels_to_integers(HeddenGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in HeddenGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "HeddenData = from_networkx(HeddenGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "\n",
    "num_node_features = len(HeddenData.x[0])\n",
    "num_classes = 2\n",
    "\n",
    "HeddenData.x = HeddenData.x.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "\n",
    "# define method to train on one graph, test on the other two\n",
    "def test_on_other_two(train_data, test_data1, test_data2):\n",
    "    \n",
    "    mask_data(train_data, train_ratio=0.6, val_ratio=0.2)\n",
    "    mask_data(test_data1, train_ratio=0, val_ratio=0)\n",
    "    mask_data(test_data2, train_ratio=0, val_ratio=0)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_data = train_data.to(device)\n",
    "    test_data1 = test_data1.to(device)\n",
    "    test_data2 = test_data2.to(device)\n",
    "\n",
    "    train_data.validate(raise_on_error=True)\n",
    "    test_data1.validate(raise_on_error=True)\n",
    "    test_data2.validate(raise_on_error=True)\n",
    "\n",
    "    model = Twitter_GCN(num_node_features,num_classes).to(device) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    # train on one model\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        loss = F.nll_loss(out[train_data.train_mask], train_data.y[train_data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # test on trained on model\n",
    "    model.eval()\n",
    "    pred = model(train_data).argmax(dim=1)\n",
    "    correct = (pred[train_data.test_mask] == train_data.y[train_data.test_mask]).sum()\n",
    "    acc = int(correct) / int(train_data.test_mask.sum())\n",
    "    print(f'Accuracy on trained on model: {acc:.4f}')    \n",
    "        \n",
    "    # test on other two\n",
    "    model.eval()\n",
    "    pred = model(test_data1).argmax(dim=1)\n",
    "    correct = (pred[test_data1.test_mask] == test_data1.y[test_data1.test_mask]).sum()\n",
    "    acc = int(correct) / int(test_data1.test_mask.sum())\n",
    "    print(f'Accuracy on other model: {acc:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    pred = model(test_data2).argmax(dim=1)\n",
    "    correct = (pred[test_data2.test_mask] == test_data2.y[test_data2.test_mask]).sum()\n",
    "    acc = int(correct) / int(test_data2.test_mask.sum())\n",
    "    print(f'Accuracy on other other model: {acc:.4f}')\n",
    "\n",
    " \n",
    "print(\"trained on dejan_________\")\n",
    "print(\"Dejan, McCormick, Hedden\")\n",
    "test_on_other_two(DejanData, McCormickData, HeddenData)\n",
    "\n",
    " \n",
    "print(\"trained on mccormick_________\")\n",
    "print(\"McCormick, Dejan, Hedden\")\n",
    "test_on_other_two(McCormickData, DejanData, HeddenData)\n",
    "\n",
    " \n",
    "print(\"trained on hedden_________\")\n",
    "print(\"Hedden, Dejan, McCormick\")\n",
    "test_on_other_two(HeddenData, DejanData, McCormickData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6f479",
   "metadata": {},
   "source": [
    "if i have time: try out a neural network w/o graph data -- is that just as accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93860e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
