{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43029ed2",
   "metadata": {},
   "source": [
    "## Prediction Verification GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952fff9",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bc6249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41908ac9",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c514eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "\n",
    "# DEJAN NETWORK\n",
    "DejanGraph = nx.read_gml('Datasets/Dejan-Full-Node-Info.gml')\n",
    "DejanGraph = nx.convert_node_labels_to_integers(DejanGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in DejanGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "DejanData = from_networkx(DejanGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "#     data = from_networkx(SoccerGraph, group_node_attrs=['followers'])\n",
    "\n",
    "num_node_features = len(DejanData.x[0])\n",
    "num_classes = 2\n",
    "\n",
    "DejanData.x = DejanData.x.type(torch.FloatTensor)\n",
    "\n",
    "# HEDDEN NETWORK\n",
    "HeddenGraph = nx.read_gml('Datasets/Hedden.gml')\n",
    "HeddenGraph = nx.convert_node_labels_to_integers(HeddenGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in HeddenGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "HeddenData = from_networkx(HeddenGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "\n",
    "num_node_features = len(HeddenData.x[0])\n",
    "num_classes = 2\n",
    "\n",
    "HeddenData.x = HeddenData.x.type(torch.FloatTensor)\n",
    "\n",
    "# MCCORMICK NETWORK\n",
    "McCormickGraph = nx.read_gml('Datasets/McCormick.gml')\n",
    "McCormickGraph = nx.convert_node_labels_to_integers(McCormickGraph, label_attribute=\"id\")\n",
    "\n",
    "# rename verified to y attribute (verified) to graph before conversion \n",
    "for n, data in McCormickGraph.nodes(data=True):\n",
    "    data[\"y\"] = data.pop('verified')\n",
    "\n",
    "McCormickData = from_networkx(McCormickGraph, group_node_attrs=['follower_count','friends_count','listed_count','favourites_count','statuses_count'])\n",
    "#     data = from_networkx(SoccerGraph, group_node_attrs=['followers'])\n",
    "\n",
    "num_node_features = len(McCormickData.x[0])\n",
    "num_classes = 2\n",
    "\n",
    "McCormickData.x = McCormickData.x.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f8921",
   "metadata": {},
   "source": [
    "Linear regression models as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97de2b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination dejan: 0.4021911191578005\n",
      "coefficient of determination hedden: 0.16435991757673385\n",
      "coefficient of determination mccormick: 0.16573663521979654\n"
     ]
    }
   ],
   "source": [
    "DejanModel = LinearRegression().fit(DejanData.x, DejanData.y)\n",
    "HeddenModel = LinearRegression().fit(HeddenData.x, HeddenData.y)\n",
    "McCormickModel = LinearRegression().fit(McCormickData.x, McCormickData.y)\n",
    "\n",
    "r_sq = DejanModel.score(DejanData.x, DejanData.y)\n",
    "print(f\"coefficient of determination dejan: {r_sq}\")\n",
    "r_sq = HeddenModel.score(HeddenData.x, HeddenData.y)\n",
    "print(f\"coefficient of determination hedden: {r_sq}\")\n",
    "r_sq = McCormickModel.score(McCormickData.x, McCormickData.y)\n",
    "print(f\"coefficient of determination mccormick: {r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068fd405",
   "metadata": {},
   "source": [
    "Define data masking function - 60/20/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_data(data, train_ratio, val_ratio):\n",
    "\n",
    "    test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "    num_nodes = data.x.shape[0]\n",
    "    num_train = int(num_nodes * train_ratio)\n",
    "    num_val = int(num_nodes * val_ratio)\n",
    "    num_test = 1 - num_train - num_val\n",
    "    idx = [i for i in range(num_nodes)]\n",
    "\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    train_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "    train_mask[idx[:num_train]] = True\n",
    "\n",
    "    val_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "    val_mask[idx[num_train:num_train+num_val]] = True\n",
    "\n",
    "    test_mask = torch.full_like(data.y, False, dtype=bool)\n",
    "    test_mask[idx[num_train+num_val:]] = True\n",
    "\n",
    "    data['train_mask'] = train_mask\n",
    "    data['val_mask'] = val_mask\n",
    "    data['test_mask'] = test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264b982",
   "metadata": {},
   "source": [
    "Mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430926a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data(DejanData, 0.6, 0.2)\n",
    "mask_data(HeddenData, 0.6, 0.2)\n",
    "mask_data(McCormickData, 0.6, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64257141",
   "metadata": {},
   "source": [
    "Define GCN, hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfa143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(GCNConv(num_node_features, 16))\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(GCNConv(16, 16))\n",
    "        self.layers.append(GCNConv(16, num_classes))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "num_layers = [2, 3]\n",
    "l2_regs = [0.0001, 0.001]\n",
    "learning_rates = [0.05, 0.01, 0.001]\n",
    "\n",
    "NUM_ITERS = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = DejanData.to(device)\n",
    "\n",
    "all_trials = []\n",
    "for n in num_layers:            \n",
    "    for l2_reg in l2_regs:\n",
    "        for learning_rate in learning_rates:\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for i in range(NUM_ITERS):\n",
    "                model = GCN(n).to(device)\n",
    "                \n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "\n",
    "                model.train()\n",
    "                for epoch in range(200):\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                model.eval()\n",
    "                pred = model(data).argmax(dim=1)\n",
    "                correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "                acc = int(correct) / int(data.val_mask.sum())\n",
    "                print(n, l2_reg, learning_rate)\n",
    "                print(f'Accuracy: {acc:.4f}')\n",
    "                \n",
    "                results.append(acc)\n",
    "                \n",
    "            avg = sum(results) / len(results)\n",
    "            stdev = statistics.pstdev(results)\n",
    "            all_trials.append(((n, l2_reg, learning_rate), avg, stdev))\n",
    "\n",
    "print((\"Number of layers\", \"L2 regularization\", \"Learning rate\"), \"Average\", \"Standard Dev.\")\n",
    "for t in all_trials:\n",
    "    print(t)\n",
    "\n",
    "max = max(all_trials, key=lambda x:x[1])\n",
    "print(\"max: \", max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844ed57",
   "metadata": {},
   "source": [
    "Train a model on each network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92669f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_GCN(data):\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    data.validate(raise_on_error=True)\n",
    "\n",
    "    model = GCN(2).to(device) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # train on own model\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "    \n",
    "    \n",
    "print('dejan')\n",
    "Run_GCN(DejanData)\n",
    "print('mccormick')\n",
    "Run_GCN(McCormickData)\n",
    "print('hedden')\n",
    "Run_GCN(HeddenData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda4ba1",
   "metadata": {},
   "source": [
    "Test each model on the other networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89dfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to train on one graph, test on the other two\n",
    "def test_on_other_two(train_data, test_data1, test_data2):\n",
    "\n",
    "    train_data = train_data.to(device)\n",
    "    test_data1 = test_data1.to(device)\n",
    "    test_data2 = test_data2.to(device)\n",
    "\n",
    "    train_data.validate(raise_on_error=True)\n",
    "    test_data1.validate(raise_on_error=True)\n",
    "    test_data2.validate(raise_on_error=True)\n",
    "\n",
    "    model = GCN(2).to(device) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    # train on one model\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        loss = F.nll_loss(out[train_data.train_mask], train_data.y[train_data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # test on trained on model\n",
    "    model.eval()\n",
    "    pred = model(train_data).argmax(dim=1)\n",
    "    correct = (pred[train_data.test_mask] == train_data.y[train_data.test_mask]).sum()\n",
    "    acc = int(correct) / int(train_data.test_mask.sum())\n",
    "    print(f'Accuracy on trained on model: {acc:.4f}')    \n",
    "        \n",
    "    # test on other two\n",
    "    model.eval()\n",
    "    pred = model(test_data1).argmax(dim=1)\n",
    "    correct = (pred[test_data1.test_mask] == test_data1.y[test_data1.test_mask]).sum()\n",
    "    acc = int(correct) / int(test_data1.test_mask.sum())\n",
    "    print(f'Accuracy on other model: {acc:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    pred = model(test_data2).argmax(dim=1)\n",
    "    correct = (pred[test_data2.test_mask] == test_data2.y[test_data2.test_mask]).sum()\n",
    "    acc = int(correct) / int(test_data2.test_mask.sum())\n",
    "    print(f'Accuracy on other other model: {acc:.4f}')\n",
    "\n",
    " \n",
    "print(\"trained on dejan_____________\")\n",
    "print(\"Dejan, McCormick, Hedden\")\n",
    "test_on_other_two(DejanData, McCormickData, HeddenData)\n",
    "\n",
    " \n",
    "print(\"trained on mccormick_________\")\n",
    "print(\"McCormick, Dejan, Hedden\")\n",
    "test_on_other_two(McCormickData, DejanData, HeddenData)\n",
    "\n",
    " \n",
    "print(\"trained on hedden____________\")\n",
    "print(\"Hedden, Dejan, McCormick\")\n",
    "test_on_other_two(HeddenData, DejanData, McCormickData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a320c8",
   "metadata": {},
   "source": [
    "Train and test on all three networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab56d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel node indexes so graphs don't overlap\n",
    "# add 685 to every Hedden (# of nodes in Dejan)\n",
    "HeddenDataNewEdgeIndex = torch.add(HeddenData.edge_index, 685)\n",
    "# add 685 + 2446 = 3131 to every McCormick (# of nodes in Dejan + Hedden)\n",
    "McCormickDataNewEdgeIndex = torch.add(McCormickData.edge_index, 3131)\n",
    "\n",
    "# combine edge lists\n",
    "CombinedDataEdgeInd = torch.cat((DejanData.edge_index, HeddenDataNewEdgeIndex, McCormickDataNewEdgeIndex), 1)\n",
    "\n",
    "# combine x\n",
    "CombinedX = torch.cat((DejanData.x, HeddenData.x, McCormickData.x), 0)\n",
    "\n",
    "# combine y\n",
    "CombinedY = torch.cat((DejanData.y, HeddenData.y, McCormickData.y), 0)\n",
    "\n",
    "# make new PyTorch data object\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "CombinedData = Data(x=CombinedX, edge_index=CombinedDataEdgeInd, y=CombinedY)\n",
    "mask_data(CombinedData, 0.6, 0.2)\n",
    "print(CombinedData)\n",
    "\n",
    "\n",
    "\n",
    "# run GCN with combined data\n",
    "Run_GCN(CombinedData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
